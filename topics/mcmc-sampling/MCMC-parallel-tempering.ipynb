{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Example: Parallel tempering for multimodal distributions\n",
    "\n",
    "## Adapted from the TALENT course on Learning from Data: Bayesian Methods and Machine Learning\n",
    "### York, UK, June 10-28, 2019\n",
    "\n",
    "The original notebook was by Christian Forssen.  Revisions are by Dick Furnstahl for Physics 8805.  (More documentation is needed!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: This version of the notebook uses the PTSampler available from emcee before version 3 (released September 2019). This sampler is now available in a different distribution, called ptemcee (see https://github.com/willvousden/ptemcee).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns;  sns.set(context='talk')\n",
    "\n",
    "import emcee\n",
    "from emcee import PTSampler\n",
    "import corner\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Gaussian prior centered at (0,0) with variance sqrt(10)\n",
    "mup = np.zeros(2)\n",
    "sigp=np.sqrt(10.)\n",
    "sigmap = np.diag([sigp**2, sigp**2])\n",
    "sigmapinv = np.linalg.inv(sigmap)\n",
    "normp = 1/np.sqrt(np.linalg.det(2*np.pi*sigmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define the log prior\n",
    "def logp(x):\n",
    "    dxp = x - mup\n",
    "    return -np.dot(dxp, np.dot(sigmapinv, dxp))/2.0 \\\n",
    "        + np.log(normp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def setup_modes(sig=0.2, ratio=3.):\n",
    "    # Means of the two Gaussian modes\n",
    "    mu1 = np.ones(2)\n",
    "    mu2 = -np.ones(2)\n",
    "\n",
    "    # Width in each dimension (zero correlation)\n",
    "    _sig = sig\n",
    "    sigma1 = np.diag([_sig**2, _sig**2])\n",
    "    sigma2 = np.diag([_sig**2, _sig**2])\n",
    "    sigma1inv = np.linalg.inv(sigma1)\n",
    "    sigma2inv = np.linalg.inv(sigma2)\n",
    "\n",
    "    # amplitudes of the two modes and the corresponding norm factor\n",
    "    _amp1 = ratio / (1+ratio)\n",
    "    _amp2 = 1. / (1+ratio)\n",
    "    norm1 = _amp1 / np.sqrt(np.linalg.det(2*np.pi*sigma1))\n",
    "    norm2 = _amp2 / np.sqrt(np.linalg.det(2*np.pi*sigma2))\n",
    "    return (mu1,mu2,sigma1inv,sigma2inv,norm1,norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "params_modes = setup_modes()\n",
    "\n",
    "# Define the log likelihood function\n",
    "def logl(x,params=params_modes):\n",
    "    (mu1,mu2,sigma1inv,sigma2inv,norm1,norm2)=params\n",
    "    dx1 = x - mu1\n",
    "    dx2 = x - mu2\n",
    "    return np.logaddexp(-np.dot(dx1, np.dot(sigma1inv, dx1))/2.0 \\\n",
    "                        + np.log(norm1),\\\n",
    "                        -np.dot(dx2, np.dot(sigma2inv, dx2))/2.0 \\\n",
    "                        + np.log(norm2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def log_posterior(x):\n",
    "    return logp(x) + logl(x)\n",
    "\n",
    "@np.vectorize\n",
    "def posterior(y,x):\n",
    "    xv=np.array([x,y])\n",
    "    return np.exp(logl(xv)+logp(xv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MH Sampling and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('emcee sampling (version: )', emcee.__version__)\n",
    "\n",
    "ndim = 2  # number of parameters in the model\n",
    "nwarmup = 1000\n",
    "nsteps = 10000\n",
    "\n",
    "# MH-Sampler setup\n",
    "stepsize = .05\n",
    "cov = stepsize * np.eye(ndim)\n",
    "p0 = np.random.rand(ndim)\n",
    "\n",
    "# initialize the sampler\n",
    "sampler = emcee.MHSampler(cov, ndim, log_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Sample the posterior distribution\n",
    "\n",
    "# Warm-up\n",
    "if nwarmup > 0:\n",
    "    print(f'Performing {nwarmup} warnup iterations.')\n",
    "    pos, prob, state = sampler.run_mcmc(p0, nwarmup)\n",
    "    sampler.reset()\n",
    "else:\n",
    "    pos = p0\n",
    "    \n",
    "# Perform iterations, starting at the final position from the warmup.\n",
    "print(f'MH sampler performing {nsteps} samples.')\n",
    "%time sampler.run_mcmc(pos, nsteps)\n",
    "print(\"done\")\n",
    "\n",
    "print(f\"Mean acceptance fraction: {sampler.acceptance_fraction:.3f}\")\n",
    "\n",
    "samples = sampler.flatchain\n",
    "    \n",
    "# make a corner plot with the posterior distribution\n",
    "fig = corner.corner(samples, quantiles=[0.16, 0.5, 0.84], labels=[r\"$\\theta_0$\", r\"$\\theta_1$\"],\n",
    "                       show_titles=True, title_kwargs={\"fontsize\": 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(2,2,figsize=(12,5*ndim))\n",
    "for irow in range(ndim):\n",
    "    ax[irow,0].plot(np.arange(samples.shape[0]),samples[:,irow])\n",
    "    ax[irow,0].set_ylabel(r'$\\theta_{0}$'.format(irow))\n",
    "    ax[irow,1].hist(samples[:,irow],orientation='horizontal',bins=30)\n",
    "\n",
    "ax[0,1].set_title('Histogram')\n",
    "ax[0,0].set_title('Trace Plot')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for irow in range(ndim):\n",
    "    print(f\"Standard Error of the Mean for theta_{irow}: {samples[:,irow].std()/np.sqrt(samples.shape[0]):.1e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Check for between chain variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "no_of_chains=2\n",
    "chains=[]\n",
    "\n",
    "for ichain in range(no_of_chains):\n",
    "    sampler.reset()\n",
    "    p0 = np.random.rand(ndim)/10 + (-1)**ichain\n",
    "    # Warm-up\n",
    "    if nwarmup > 0:\n",
    "        print(f'Chain {ichain} performing {nwarmup} warnup iterations.')\n",
    "        pos, prob, state = sampler.run_mcmc(p0, nwarmup)\n",
    "        sampler.reset()\n",
    "    else:\n",
    "        pos = p0\n",
    "    \n",
    "    # Perform iterations, starting at the final position from the warmup.\n",
    "    print(f'MH sampler {ichain} performing {nsteps} samples.')\n",
    "    sampler.run_mcmc(pos, nsteps)\n",
    "    print(\"done\")\n",
    "    print(f\"Mean acceptance fraction: {sampler.acceptance_fraction:.3f}\")\n",
    "\n",
    "    chains.append(sampler.flatchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = chains[0]\n",
    "chain2 = chains[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(2,1,figsize=(12,10))\n",
    "for icol in range(ndim):\n",
    "    ax[icol].plot(np.arange(chain1.shape[0]),chain1[:,icol])\n",
    "    ax[icol].plot(np.arange(chain2.shape[0]),chain2[:,icol],alpha=.7)\n",
    "    ax[icol].set_ylabel(r'$\\theta_{0}$'.format(icol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This is a multimodal distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-4, 4, 0.05)\n",
    "Y = np.arange(-4, 4, 0.05)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z=posterior(Y,X)\n",
    "\n",
    "ax.set_xlim([-1.6,1.6])\n",
    "ax.set_ylim([-1.6,1.6])\n",
    "ax.contour(X, Y, Z, 10)\n",
    "CS=ax.contourf(X, Y, Z, cmap=plt.cm.cubehelix_r);\n",
    "cbar = plt.colorbar(CS)\n",
    "ax.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PT Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can construct a sampler object that will drive the PTMCMC; \n",
    "# arbitrarily, we choose to use 21 temperatures \n",
    "# (the default is for each temperature to increase by a factor of sqrt(2), \n",
    "# so the highest temperature will be T=1024, resulting in an effective \n",
    "# \\sigma_T=32\\sigma=3.2, which is about the separation of our modes). \n",
    "\n",
    "#ntemps = 21\n",
    "#temps = np.array([np.sqrt(2)**i for i in range(ntemps)])\n",
    "\n",
    "# Modified temperature ladder to improve the integration for evidence calculation\n",
    "# need more low temperatures, i.e. finer grid near beta=1\n",
    "ntemps_lo = 8\n",
    "ntemps_hi = 21\n",
    "temps_lo = np.array([2**(i/8.) for i in range(ntemps_lo)])\n",
    "temps_hi = np.array([np.sqrt(2)**i for i in range(ntemps_hi)])\n",
    "temps = np.concatenate((temps_lo,temps_hi[temps_hi>max(temps_lo)]))\n",
    "ntemps=len(temps)\n",
    "\n",
    "# Let us use 10 walkers in the ensemble at each temperature:\n",
    "nwalkers = 10\n",
    "ndim = 2\n",
    "\n",
    "nburnin = 1000\n",
    "niterations=1000\n",
    "nthin = 10 # only record every nthin iteration\n",
    "\n",
    "nthreads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas=1/temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler=PTSampler(ntemps, nwalkers, ndim, logl, logp, threads=nthreads,betas=betas)\n",
    "\n",
    "#Making the sampling multi-threaded is as simple as adding the threads=Nthreads \n",
    "# argument to PTSampler. We could have modified the temperature ladder using the \n",
    "# betas optional argument (which should be an array of \\beta=1/T values). \n",
    "\n",
    "#First, we run the sampler for 1000 burn-in iterations:\n",
    "\n",
    "#p0 = np.random.uniform(low=-1.0, high=1.0, size=(ntemps, nwalkers, ndim))\n",
    "p0 = np.random.normal(loc=mup, scale=sigp, size=(ntemps, nwalkers, ndim))\n",
    "\n",
    "print(\"Running burn-in phase\")\n",
    "for p, lnprob, lnlike in sampler.sample(p0, iterations=nburnin):\n",
    "    pass\n",
    "sampler.reset()\n",
    "\n",
    "print(\"Running MCMC chains\")\n",
    "#Now we sample for nwalkers*niterations, recording every nthin-th sample:\n",
    "\n",
    "for p, lnprob, lnlike in sampler.sample(p, lnprob0=lnprob,\n",
    "                                        lnlike0=lnlike,\n",
    "                                        iterations=niterations, thin=nthin):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#The resulting samples (nwalkers*niterations/nthin of them)\n",
    "# are stored as the sampler.chain property:\n",
    "\n",
    "assert sampler.chain.shape == (ntemps, nwalkers, niterations/nthin, ndim)\n",
    "# Chain has shape (ntemps, nwalkers, nsteps, ndim)\n",
    "# Zero temperature mean:\n",
    "mu0 = np.mean(np.mean(sampler.chain[0,...], axis=0), axis=0)\n",
    "print(\"The zero temperature mean is: {}\".format(mu0))\n",
    "\n",
    "(mu1,mu2,sigma1inv,sigma2inv,norm1,norm2)=params_modes\n",
    "print(\"To be compared with likelihood distribution: \")\n",
    "print(\"... peak 1: {}, peak 2: {}\".format(mu1, mu2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mcmc_data0 = sampler.chain[0,...].reshape(-1,ndim)\n",
    "figure = corner.corner(mcmc_data0)\n",
    "\n",
    "# Extract the axes\n",
    "axes = np.array(figure.axes).reshape((ndim, ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the posterior for four different temperatures: beta[0],beta[4],beta[10],beta[19]\n",
    "ntempered=np.array([ntemps-1,ntemps-11,8,0])\n",
    "for nt in ntempered:\n",
    "    mcmc_data_nt = sampler.chain[nt,...].reshape(-1,ndim)\n",
    "    figure = corner.corner(mcmc_data_nt)\n",
    "    # Extract the axes\n",
    "    axes = np.array(figure.axes).reshape((ndim, ndim))\n",
    "    axes[ndim-1,ndim-1].set_title('T=%i' %temps[nt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:8805-env] *",
   "language": "python",
   "name": "conda-env-8805-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
